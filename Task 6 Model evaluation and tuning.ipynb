{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "499a7bf7-ac24-429f-9c63-b0fdeabc7de8",
   "metadata": {},
   "source": [
    "### Import libraries and load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f30d11d-0626-4aab-81dc-cb5ec0c7a271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n",
      "   gender race/ethnicity parental level of education         lunch  \\\n",
      "0  female        group B           bachelor's degree      standard   \n",
      "1  female        group C                some college      standard   \n",
      "2  female        group B             master's degree      standard   \n",
      "3    male        group A          associate's degree  free/reduced   \n",
      "4    male        group C                some college      standard   \n",
      "\n",
      "  test preparation course  math score  reading score  writing score  \n",
      "0                    none          72             72             74  \n",
      "1               completed          69             90             88  \n",
      "2                    none          90             95             93  \n",
      "3                    none          47             57             44  \n",
      "4                    none          76             78             75  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/User/Downloads/StudentsPerformance.csv\")\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d12b01-c344-4f5b-8922-3c1a7ebb3087",
   "metadata": {},
   "source": [
    "### Step : 2 Define target and features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef6bb234-1bed-40bb-848c-005eece7ebc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution:\n",
      "math_pass\n",
      "0    591\n",
      "1    409\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['math_pass'] = (df['math score'] >= 70).astype(int)\n",
    "X = df.drop(['math score', 'math_pass'], axis=1)\n",
    "y = df['math_pass']\n",
    "\n",
    "print(\"Target distribution:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c96dae5-35b1-42af-88a5-046bdd461750",
   "metadata": {},
   "source": [
    "### Step 3 : Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17467d2d-736f-4627-bd55-bfaec0ad3c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns being encoded:\n",
      "['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical_columns = X.select_dtypes(include='object').columns\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)\n",
    "])\n",
    "\n",
    "print(\"Categorical columns being encoded:\")\n",
    "print(categorical_columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694ca3c8-3294-42e3-97d5-1a24a0f4586a",
   "metadata": {},
   "source": [
    "### Step 4 : Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f2c3a73-1ff4-43f3-9728-5b2220664802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: (800, 7)\n",
      "Test size: (200, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training size:\", X_train.shape)\n",
    "print(\"Test size:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2e1047-f38a-4217-9a3f-b015f65e99d2",
   "metadata": {},
   "source": [
    "### Step 5 : Train and evaluate multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b083d740-f9d2-4035-81cc-58cf0fa413a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Comparison Results:\n",
      "                    Model  Accuracy  F1 Score   ROC-AUC\n",
      "0     Logistic Regression     0.685  0.519084  0.714810\n",
      "1           Random Forest     0.610  0.518519  0.614820\n",
      "2  Support Vector Machine     0.630  0.493151  0.658743\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Support Vector Machine': SVC(probability=True)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'F1 Score': f1_score(y_test, y_pred),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_proba)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='F1 Score', ascending=False)\n",
    "print(\"Model Comparison Results:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75b7536-def0-4720-b7fb-ac3e50be62a8",
   "metadata": {},
   "source": [
    "### Step 6 : Hyperparameter tuning with gridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "927a0b67-439f-461f-ae92-03aa7f7161e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'model__max_depth': 10, 'model__n_estimators': 50}\n",
      "Best F1 Score from GridSearchCV: 0.49838438181108247\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'model__n_estimators': [50, 100],\n",
    "    'model__max_depth': [None, 10, 20]\n",
    "}\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Best F1 Score from GridSearchCV:\", grid.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
